# 基于STM32的二自由度人脸追踪与情绪识别云台

这是一个为课程设计的项目，它实现了一个基于PC和STM32的二自由度（2-DOF）云台，能够实时追踪镜头前的人脸，并识别其情绪，最终通过OLED屏幕显示出来。

![系统运行实时图像](./Docs/images/system_running.png)
*图注：系统运行时的上位机界面，可实时显示追踪框、误差和情绪识别结果。*

## ✨ 项目特色 (Features)

* **实时人脸追踪**：利用OpenCV在PC端进行高速人脸检测，STM32驱动舵机云台进行稳定跟随。
* **平滑PD控制**：采用PD（比例-微分）控制算法，有效避免了舵机运动的抖动和过冲，使追踪过程更加平滑自然。
* **情绪识别与显示**：通过预训练的Keras深度学习模型识别人脸的四种基本情绪（开心、难过、惊讶、生气），并在OLED屏幕上用生动的图标显示。
* **软硬件协同设计**：充分利用PC强大的计算能力进行视觉处理，结合STM32优异的实时控制性能，构建了一个高性价比的解决方案。
* **详尽的性能分析**：项目包含了对追踪系统动态响应（阶跃、冲激）、误差、抗干扰能力以及情绪识别置信度的完整数据记录与可视化分析。

## ⚙️ 系统架构 (System Architecture)

本系统采用“上位机+下位机”的经典架构：

* **上位机 (PC)**：负责计算密集型的视觉处理任务。通过USB摄像头捕获视频，利用OpenCV进行人脸检测，提取人脸区域送入Keras模型进行情绪分析。最终将计算出的**人脸坐标**和**情绪代码**通过串口发送出去。
* **下位机 (STM32)**：作为执行终端，负责实时控制。它接收来自上位机的指令，通过PD算法计算舵机运动量，并生成PWM信号驱动云台转动。同时，根据情绪代码驱动OLED显示对应的表情。

![系统总体方案框图](./Docs/images/system_architecture.png)

## 🛠️ 硬件清单 (Hardware Requirements)

| 组件                  | 型号/规格                         | 数量 | 用途                               |
| :-------------------- | :-------------------------------- | :--- | :--------------------------------- |
| **主控芯片** | STM32F103C8T6 最小系统板          | 1    | 核心控制器，负责接收指令和驱动外设 |
| **舵机** | SG90 微型舵机                     | 2    | 控制云台水平和垂直方向的运动       |
| **云台支架** | 二自由度云台                      | 1    | 舵机和摄像头的机械结构             |
| **摄像头** | Y-1646S12-V2 (或任意USB摄像头)    | 1    | 采集视频图像                       |
| **显示屏** | 0.96英寸 I2C OLED显示屏           | 1    | 显示识别出的情绪图标               |
| **通信模块** | CH340G USB转TTL模块               | 1    | 实现PC与STM32之间的串口通信      |
| **电源模块** | 外部5V直流电源                    | 1    | 为整个系统提供稳定供电             |
| **其他** | 杜邦线、面包板                    | 若干 | 用于连接电路                       |

![系统整体实物连接图](./Docs/images/hardware_setup.jpg)

## 💻 软件与依赖 (Software & Dependencies)

### 上位机 (PC)

* **语言**: Python 3.8+
* **核心库**:
    * OpenCV-Python
    * TensorFlow / Keras
    * PySerial
    * NumPy
    * Matplotlib (用于数据分析和绘图)
* **模型文件**:
    * `haarcascade_frontalface_default.xml` (人脸检测模型)
    * `modelv2.h5` (情绪识别模型)

建议使用`pip`安装所有依赖：
```bash
pip install opencv-python tensorflow pyserial numpy matplotlib pillow
```

### 下位机 (STM32)

* **IDE**: Keil MDK 5
* **库**: STM32F10x 标准外设库 (StdPeriph_Lib)

## 🚀 部署与运行 (Setup & Run)

1.  **硬件连接**：参照上文的硬件清单和系统实物图，连接好所有硬件模块。
2.  **烧录固件**：使用Keil MDK打开`/STM32_Firmware`目录下的工程，编译后通过ST-Link或J-Link将生成的`.hex`文件下载到STM32单片机中。
3.  **配置上位机**：
    * 将`/PC_Host`文件夹下的所有文件（.py脚本和模型文件）放在同一目录下。
    * 打开`track_face.py`脚本，修改`ser.port = 'COM5'`为您PC上CH340G模块对应的串口号。
4.  **运行系统**：
    * 先为STM32开发板和舵机接通电源。
    * 在PC上运行`track_face.py`脚本。
    * 程序启动后，摄像头画面会显示在屏幕上，系统开始自动追踪人脸。

## 🔬 核心技术解析 (Core Concepts)

### 通信协议

为了实现上位机与下位机之间高效、准确的通信，本设计定义了一个简单的串行通信协议。

* **格式**: `#<X坐标>$<Y坐标>&<情绪代码>\r\n`
* **示例**: `#315$245&1\r\n`
* **解析**:
    * `#`：帧头，标志一帧数据的开始。
    * `$`：分隔符，用于分隔X和Y坐标。
    * `&`：分隔符，用于分隔Y坐标和情绪代码。
    * `\r\n`：帧尾，标志数据结束。下位机通过检测`0x0d 0x0a`来确认接收完成。
    * 所有数据均为ASCII字符串格式，下位机接收后使用`atoi()`函数进行转换。

### PD控制算法

为了让舵机云台的追踪动作平滑、稳定，避免来回振荡，系统采用了PD控制器，其核心是`pid()`函数（由于积分项`Ki`设为0）。

* **P (比例) 项**: `P_out = Kp * error`
    * 提供主要的控制力，误差越大，舵机转动越快，保证了系统的响应速度。

* **D (微分) 项**: `D_out = Kd * (error - last_error)`
    * 预测误差的变化趋势，相当于“阻尼”或“刹车”。当目标快速接近时，它会产生一个反向作用力，有效抑制过冲和振荡，使追踪过程更稳定。

最终的控制量是增量式的，即 `pwm_new = pwm_current + (P_out + D_out)`，这使得控制更加平滑。

## 📊 性能与结果 (Performance & Results)

经过测试，系统表现出良好的追踪和识别性能。

#### 追踪性能分析

通过上位机记录的数据，可以定量分析系统的追踪性能。

![人脸中心坐标随时间变化图](./Docs/images/trajectory_plot.jpg)
*图注：上图展示了人脸中心坐标(红线/蓝线)随时间的变化。可以看出，系统能快速响应人脸移动，并将坐标稳定在目标值(黑虚线)附近。*

![系统误差响应图](./Docs/images/response_analysis.jpg)
*图注：误差曲线显示了实际坐标与目标坐标的偏差。误差值大部分时间在0附近小范围波动，证明了PD控制器的有效性。下方的相平面图显示误差轨迹向原点收敛，证明系统稳定。*

#### 控制系统特性仿真

为从理论上验证控制策略的有效性，对一个具有相似动态特性的二阶系统模型进行了仿真分析。

![系统单位阶跃响应仿真分析](./Docs/images/step_response_analysis.jpg)
*图注：系统的单位阶跃响应曲线。系统具有约1.81秒的峰值时间和4.04秒的调节时间，16.3%的最大超调量表明系统是一个典型的欠阻尼系统，是在响应速度和稳定性之间取得的良好平衡。*

![系统抗干扰分析](./Docs/images/disturbance_analysis.jpg)
*图注：系统对阶跃、正弦、随机噪声以及组合干扰均表现出良好的抑制能力，响应曲线平滑且能快速回归稳态。*

#### 情绪识别性能分析

![情绪识别置信度随时间变化](./Docs/images/confidence_trend.png)
*图注：模型对情绪识别的置信度随时间波动，反映了模型对不同表情姿态的识别能力差异。*

![测试周期内情绪分布统计](./Docs/images/emotion_distribution.png)
*图注：在一次测试中，系统主要识别出了“惊讶”和“难过”两种情绪，与测试者的表情基本吻合。*

![情绪变化统计热图](./Docs/images/emotion_heatmap.png)
*图注：热图直观地展示了在不同时间点识别出的情绪类别及其置信度（颜色深浅）。*

## 🔮 未来展望 (Future Work)

1.  **系统独立化**：使用更强大的嵌入式平台（如树莓派、Jetson Nano）替代PC，将视觉算法完全移植到设备端，实现系统独立运行。
2.  **追踪算法优化**：引入卡尔曼滤波（Kalman Filter）来预测目标运动轨迹，即使人脸短暂丢失也能继续追踪。
3.  **交互方式升级**：增加语音控制模块，通过语音指令控制系统启停；或接入物联网平台，实现远程监控。

## 🙏 致谢 (Acknowledgements)

感谢我的课程指导老师在本项目的构思、开发和调试过程中给予的悉心指导。感谢学校提供的课程设计平台，让我有机会将理论知识应用于实践。

## 📄 许可证 (License)

该项目采用 [MIT License](LICENSE) 授权。
